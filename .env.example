# .env

TEXT_MODEL_BASE_URL=https://openrouter.ai/api/v1
TEXT_MODEL_API_KEY=your_text_model_api_key_here
# Choose a model compatible with function calling / JSON mode 
# Example: "openai/gpt-4o-mini" or "google/gemma-3-27b-it" are good if using openrouter
TEXT_MODEL_NAME="openai/gpt-4o-mini"

# Whisper Model Configuration
TRANSCRIPTION_BASE_URL=http://your_local_api_url:port/v1/
TRANSCRIPTION_API_KEY=your_transcription_api_key_here
WHISPER_MODEL="Systran/faster-distil-whisper-large-v3"

# Application Settings
# The timezone for displaying dates and times in the UI.
# Use a valid TZ database name (e.g., "America/New_York", "Europe/London", "UTC").
TIMEZONE="UTC"

# Set the logging level for the application.
# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL="INFO"

# Set to "false" to disable new account registration
ALLOW_REGISTRATION="false"

# Max tokens for LLM responses (optional, defaults are set in app.py)
SUMMARY_MAX_TOKENS="8000"
CHAT_MAX_TOKENS="5000"

# Large File Chunking Configuration (for endpoints with file size limits like OpenAI)
# Enable automatic chunking for large files that exceed API limits
ENABLE_CHUNKING="true"

# Maximum chunk size in MB (default: 20MB for safety margin with 25MB limits)
# Adjust based on your transcription endpoint's file size limit
CHUNK_SIZE_MB="20"

# Overlap between chunks in seconds to ensure no speech is lost at boundaries
# Recommended: 3-5 seconds for natural speech
CHUNK_OVERLAP_SECONDS="3"

# Automated File Processing ("Black Hole" Directory Monitoring)
# Enable automatic processing of audio files dropped into a monitored directory
# ENABLE_AUTO_PROCESSING="true"

# Directory to monitor for new audio files (inside container)
# AUTO_PROCESS_WATCH_DIR="/data/auto-process"

# How often to check for new files (in seconds)
# AUTO_PROCESS_CHECK_INTERVAL="30"

# Processing mode: admin_only, user_directories, or single_user
# AUTO_PROCESS_MODE="admin_only"

# For single_user mode: specify which username to assign all files to
# AUTO_PROCESS_DEFAULT_USERNAME="your_username"

# Models
# openai/gpt-4o-mini
# google/gemma-3-27b-it
